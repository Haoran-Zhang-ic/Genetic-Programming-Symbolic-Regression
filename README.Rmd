---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# gpsr

<!-- badges: start -->
<!-- badges: end -->

The goal of gpsr is to solve symbolic regression problem using genetic programming technique. Genetic programming is a widely used machine learning method in a variety of tasks: optimization, regression and so on. It begins by building a population of naive random tree-like formulas to represent a relationship between known independent variables and their dependent variable targets in order to predict new data. And the population of formulas keep evolving by selecting optimal individuals from themselves.

## Installation

You can install the development version of gpsr like so:

``` r
# use remotes 
remotes::install_github("Haoran-Zhang-ic/Genetic-Programming-Symbolic-Regression")
# or use devtools
devtools::install_github("Haoran-Zhang-ic/Genetic-Programming-Symbolic-Regression")
```

## Example

This is a basic example which shows you how to solve a common problem:

```{r example}
library(gpsr)
## basic example code
set.seed(0)
# randomly generate samples
data <- matrix(runif(100, -1, 1), nrow = 50, ncol = 2)
# our target formula: X1^2 - X2^2 + X1 - 1
y <- data[, 1]**2 - data[, 2]**2 + data[, 1] - 1
sr <- SymbolicRegressor$new(
  pop_size = 2000,
  generations = 10,
  p_crossover = 0.7,
  p_subtree_mutation = 0.1,
  p_hoist_mutation = 0.05,
  p_point_mutation = 0.1,
  p_point_replace = 0.1,
  parsimony_coefficient = 0.001
)
# fit the target
sr$fit(data, y)
# find the best program
paste("Best program:",sr$best_program$tree_expression())
```

Our target formula is: $y = X_1^2 - X_2^2 + X_1 - 1$.

The best expression we get is $y = (X_1 - 0.974) - (X_2^2 - X_1^2)$.

After reform our expression $y = X_1^2 - X_2^2 + X_1 - 0.974$, we (almost) find the formula we are looking for! 
